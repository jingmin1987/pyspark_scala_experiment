{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02cde3de-6302-4339-8c04-58521d9c8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "\n",
    "from estimator.xgbclassifier import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57334f3-e8cf-464a-9ba4-2611b8a85d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "x = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.Series(iris.target)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "140c7f1b-7a59-4e54-83d6-ab000f56029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_clf = XGBClassifier.make(\n",
    "    n_estimators=100, \n",
    "    reg_lambda=1.0, \n",
    "    gamma=0.5,\n",
    "    max_depth=3,\n",
    "    num_class=3,\n",
    "    n_jobs=2,\n",
    "    objective='multi:softprob',\n",
    ")\n",
    "\n",
    "python_model = python_clf.fit(x_train, y_train)\n",
    "\n",
    "python_result = python_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c74aefd-0a1e-495b-a15a-0d4b3dbe5158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/home/jingmin1987/hadoop/spark-3.3.0/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/home/jingmin1987/hadoop/hadoop-3.3.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/23 15:22:44 WARN Utils: Your hostname, JazyJojo resolves to a loopback address: 127.0.1.1; using 192.168.1.155 instead (on interface wifi0)\n",
      "22/07/23 15:22:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/07/23 15:22:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('my_test').config('spark.jars', '../xgboost4j_2.12-1.6.1.jar,../xgboost4j-spark_2.12-1.6.1.jar,../scala-util/out/artifacts/scala_util_jar/scala-util.jar').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45447e9f-3c68-409a-92ef-0f21aff62b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scala_clf = XGBClassifier.make(\n",
    "    backend='scala',\n",
    "    spark=spark,\n",
    "    eta=0.1,\n",
    "    reg_lambda=1.0, \n",
    "    gamma=0.5,\n",
    "    max_depth=3,\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,\n",
    "    num_round=100,\n",
    "    num_workers=2\n",
    ").set_features_col('features') \\\n",
    ".set_label_col('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e2687da7-75b5-4ee5-b01a-dbd0a8557e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train = x_train.assign(label=y_train)\n",
    "xy_test = x_test.assign(label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d89c0f0-063e-40ce-a7f3-6bbd9abe4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train_spark = spark.createDataFrame(xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9aad532-e03c-4023-b74b-197f6ee966ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal length (cm): double (nullable = true)\n",
      " |-- sepal width (cm): double (nullable = true)\n",
      " |-- petal length (cm): double (nullable = true)\n",
      " |-- petal width (cm): double (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xy_train_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a1c29820-2a38-4498-b477-47e6ad5de405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)',\n",
       " 'label']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_train_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8606c22f-f324-4d9e-8b1d-9d018c62b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = scala_clf.transform(xy_train_spark, xy_train_spark.columns[:-1], 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7d77e685-d86c-454f-ad0f-d7fed3128047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/23 16:18:04 WARN XGBoostSpark: train_test_ratio is deprecated since XGBoost 0.82, we recommend to explicitly pass a training and multiple evaluation datasets by passing 'eval_sets' and 'eval_set_names'\n",
      "Tracker started, with env={DMLC_NUM_SERVER=0, DMLC_TRACKER_URI=192.168.1.155, DMLC_TRACKER_PORT=57625, DMLC_NUM_WORKER=2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:18:04] task 0 got new rank 0\n",
      "[16:18:04] task 1 got new rank 1\n"
     ]
    }
   ],
   "source": [
    "_ = scala_clf.fit(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "daefcd9c-7f76-47f7-b951-2b7b4e78ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_test_spark = spark.createDataFrame(xy_test)\n",
    "vector_test = scala_clf.transform(xy_test_spark, xy_test_spark.columns[:-1], 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb5d3e55-a8e5-4fc6-93ed-2d066375602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scala_clf.predict(vector_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3b75c2e5-fa7a-4507-baef-4fe630e3931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e630d975-1123-47f1-b927-bc27ee7b43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = DataFrame(result, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ecb1344-33ca-4ede-a327-137d3546b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scala_result = result_df.select('prediction').toPandas()['prediction'].astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b26de5a-415a-4db5-8a24-eef53b9fd089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_result == scala_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
